\ChapterImageStar[cap:marcoConceptual]{Marco Conceptual}{./images/fondo.png}\label{cap:marcoConceptual}
\mbox{}\\
Los conceptos a continuación no solo delimitan el ámbito de estudio, sino que también proporcionan las bases terminológicas y estructurales necesarias para la evaluación, comparación e implementación de las tecnologías consideradas. La virtualización constituye el punto de partida de este marco. Se entiende como una tecnología que permite la creación de representaciones virtuales de recursos físicos de computación, como servidores, almacenamiento o redes, facilitando la ejecución de múltiples entornos aislados sobre una misma infraestructura física. Tradicionalmente, la virtualización se ha implementado mediante hipervisores, software que posibilita la creación y gestión de máquinas virtuales (VMs), las cuales emulan hardware completo y ejecutan sistemas operativos independientes. Si bien esta aproximación ofrece un alto grado de aislamiento, conlleva una sobrecarga significativa en términos de consumo de recursos, debido a la duplicación de sistemas operativos y la necesidad de reservar recursos de forma estática para cada instancia. Frente a este modelo, emerge la virtualización basada en contenedores (VBC). A diferencia de las máquinas virtuales, los contenedores no virtualizan el hardware subyacente, sino que comparten el kernel del sistema operativo anfitrión. Esto se logra mediante mecanismos de aislamiento a nivel de sistema operativo, como namespaces y cgroups en Linux, que permiten aislar procesos, sistemas de archivos, redes y recursos computacionales para cada contenedor. El resultado son instancias extremadamente ligeras, con tiempos de arranque reducidos y una eficiencia superior en el uso de CPU, memoria y almacenamiento, en comparación con las VMs tradicionales. Un concepto central en el ecosistema de contenedores es el de la imagen de contenedor. Una imagen es un paquete inmutable que incluye todo lo necesario para ejecutar una aplicación: código, bibliotecas, herramientas del sistema y configuraciones. Las imágenes se construyen en capas a partir de un archivo de instrucciones (Dockerfile, por ejemplo), lo que favorece la reutilización y el control de versiones. Estas imágenes se almacenan en registros (como Docker Hub), desde donde pueden ser descargadas y ejecutadas en cualquier entorno compatible. La orquestación de contenedores representa otro pilar conceptual indispensable. Gestionar manualmente unos pocos contenedores es factible, pero a escala, se requiere de herramientas automatizadas para desplegar, escalar, monitorizar y mantener la salud de cientos o miles de contenedores. Aquí, Kubernetes se erige como el estándar de facto. Es una plataforma open-source que automatiza la gestión de aplicaciones contenerizadas, proporcionando mecanismos para el descubrimiento de servicios, balanceo de carga, auto-escalamiento y despliegues automatizados. Kubernetes no interactúa directamente con los contenedores, sino a través de un runtime de contenedores que cumple con la Open Container Initiative (OCI), un estándar industrial que especifica formatos y rutinas para contenedores. Es en este nivel de runtime donde se sitúan las tecnologías VBC evaluadas en este trabajo, como Docker, Podman, containerd y LXC. Cada una ofrece una implementación distinta para crear y ejecutar contenedores OCI. Docker, por ejemplo, popularizó el uso de contenedores al ofrecer una herramienta todo-en-uno que incluye un daemon, un CLI y herramientas de construcción de imágenes. Containerd, por su parte, es un runtime más minimalista y enfocado, que se diseñó para ser embebido en sistemas más grandes como Kubernetes, manejando de forma eficiente el ciclo de vida de los contenedores a bajo nivel. La transición hacia infraestructuras definidas por software y aplicaciones cloud-native está intrínsecamente ligada a estos conceptos. Una aplicación cloud-native está diseñada específicamente para aprovechar las ventajas de la nube, como la escalabilidad elástica y la alta disponibilidad, y suele estar compuesta por microservicios empaquetados en contenedores y orquestados mediante plataformas como Kubernetes. Este paradigma arquitectónico permite una entrega continua y una resiliencia superior frente a modelos monolíticos tradicionales. Para el GRID, la adopción de estas tecnologías representa una evolución natural de su infraestructura. El grupo ya cuenta con una base sólida de virtualización tradicional mediante el hipervisor XCP-ng. La incorporación de VBC no busca reemplazar esta infraestructura, sino complementarla, ofreciendo un portafolio de servicios más diversificado. Los contenedores pueden coexistir con las máquinas virtuales, permitiendo asignar la tecnología más adecuada según la carga de trabajo: VMs para cargas que requieran un alto aislamiento o kernels de SO específicos, y contenedores para aplicaciones modernas, entornos de desarrollo ágiles y servicios efímeros donde la eficiencia de recursos es crítica. Finalmente, conceptos como infraestructura inmutable y GitOps completan este marco. La infraestructura inmutable propone que los entornos de despliegue no deben ser modificados una vez creados; en su lugar, cualquier cambio requiere construir una nueva imagen y desplegarla desde cero, lo que incrementa la confiabilidad y la consistencia entre entornos. GitOps, por otro lado, es un paradigma operativo que utiliza repositorios Git como fuente de verdad para la definición de la infraestructura y las aplicaciones, automatizando los despliegues para que el estado del sistema siempre refleje el estado declarado en el repositorio. En conjunto, estos conceptos delinean un panorama tecnológico moderno y robusto sobre el cual se diseña la solución arquitectónica para el GRID. Proporcionan el vocabulario técnico y las bases estructurales necesarias para entender la evaluación, selección e integración de las tecnologías VBC en el contexto específico de un grupo de investigación académico, con sus particulares restricciones de recursos y sus objetivos misionales de docencia, investigación y extensión.

